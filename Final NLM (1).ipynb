{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f473481-e061-413e-a0a6-8b530a3f2250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbef0c24-9ef9-408e-8c1e-3a594357c2fc",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "26b09d40-6200-4de5-b872-6aa752cb227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def preprocess(self,dataset):\n",
    "        if dataset == 'friends':\n",
    "            #self.friends(dataset)\n",
    "            try:                \n",
    "                self.friends(dataset)\n",
    "                print(\"Friends data Processed Successfully :)\")\n",
    "            except Exception:\n",
    "                print(\"Processing Failed:\",str(Exception))\n",
    "                \n",
    "        elif dataset == 'bookscorpus':\n",
    "            try:                \n",
    "                booksCorpus(dataset)\n",
    "                print(\"BoxCorpus data Processed Successfully :)\")\n",
    "            except Exception:\n",
    "                print(\"Processing Failed:\",Exception)\n",
    "\n",
    "        elif dataset == 'movie_dialogues':\n",
    "            self.movies(dataset)\n",
    "            try:                \n",
    "                self.movies(dataset)\n",
    "                print(\"Movie Dialogues data Processed Successfully :)\")\n",
    "            except Exception:\n",
    "                print(\"Processing Failed:\",Exception)\n",
    "    \n",
    "    def friends(self,dataset):\n",
    "        NO_OF_SEASONS = 11\n",
    "        for i in range(1,NO_OF_SEASONS):\n",
    "            file = open(os.path.join(os.getcwd(),'Datasets/raw_data/friends/friends_season_%.2d.json'%i))\n",
    "            jtxt = json.load(file)\n",
    "            dialogueList = []\n",
    "            path = os.path.join(os.getcwd(),'Datasets/processed_data/friends/')    \n",
    "            if not os.path.isdir(path):\n",
    "                os.makedirs(path)\n",
    "            tfile = open( os.path.join(path,\"season%d.txt\"%i), 'a+')\n",
    "            for e in jtxt['episodes']:\n",
    "                for scene in e['scenes']:\n",
    "                    for utter in scene['utterances']:\n",
    "                        speakers = ' '.join(utter['speakers'])+':\\n'\n",
    "                        dialogue = utter['transcript']+'\\n\\n'\n",
    "                        if len(utter['speakers'])>0:\n",
    "                            tfile.write(speakers)\n",
    "                            tfile.write(dialogue)                \n",
    "                            dialogueList.append(utter['transcript'])\n",
    "            tfile.close()\n",
    "            tfile = open( os.path.join(path,\"season%d.txt\"%i), 'r')\n",
    "            # writes season(s) to one series file\n",
    "            friends = open( os.path.join(path,\"friends.txt\"), 'a+')\n",
    "            friends.write(tfile.read())\n",
    "            friends.close()\n",
    "            tfile.close()\n",
    "            \n",
    "    def movies(self,dataset):\n",
    "        #NO_OF_SEASONS = 11\n",
    "        path = os.path.join(os.getcwd(),'Datasets/processed_data/movies/')\n",
    "        file = open(os.path.join(os.getcwd(),'Datasets/raw_data/movies/movie_lines.txt'),'rb').readlines()\n",
    "\n",
    "        if not os.path.isdir(path):\n",
    "            os.makedirs(path)\n",
    "        tfile = open( os.path.join(path,\"movie_dialogues.txt\"), 'a+')\n",
    "        for line in file:\n",
    "            dialogue=\"\"\n",
    "            try:\n",
    "                dialogue = line.decode('utf-8').split(\"+++$+++\")[-1]\n",
    "            except Exception as e:\n",
    "                print(\"Error Here: \",line)\n",
    "                print(e)\n",
    "                break\n",
    "            newText = dialogue.replace(\"\\\\n\\'\",\"\")\n",
    "            tfile.write(newText.rstrip('\\n'))\n",
    "    \n",
    "        tfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9fd19ba7-dad9-471e-a0c1-05394a79f2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Here:  b'L19462 +++$+++ u198 +++$+++ m13 +++$+++ ELAINE +++$+++ You got a telegram from head\\xadquarters today.\\n'\n",
      "'utf-8' codec can't decode byte 0xad in position 83: invalid start byte\n",
      "Error Here:  b'L19462 +++$+++ u198 +++$+++ m13 +++$+++ ELAINE +++$+++ You got a telegram from head\\xadquarters today.\\n'\n",
      "'utf-8' codec can't decode byte 0xad in position 83: invalid start byte\n",
      "Movie Dialogues data Processed Successfully :)\n"
     ]
    }
   ],
   "source": [
    "dp = DataPreprocessor()\n",
    "#dp.preprocess('friends')\n",
    "dp.preprocess('movie_dialogues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "58ed6873-ee1e-4d2b-8fbf-60c625c04b1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[127], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatasets/processed_data/movies/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m tfile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m( os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmovie_dialogues.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma+\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m tfile\u001b[38;5;241m.\u001b[39mwrite(\u001b[43mtfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      4\u001b[0m tfile\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(),'Datasets/processed_data/movies/')\n",
    "tfile = open( os.path.join(path,\"movie_dialogues.txt\"), 'a+')\n",
    "tfile.write(tfile.read().encode('utf-8').replace('\\n\\'',\"\").replace('\\n\\\"',\"\").replace(\"\\n\",\"\"))\n",
    "tfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "38e09847-b503-4b4f-9d7e-6cf7744bbc46",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4220911807.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[131], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    tfile.write(for i in file.encode('ascii').replace('\\n\\'',\"\").replace('\\n\\\"',\"\").replace(\"\\n\",\"\"))\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "file = open(os.path.join(os.getcwd(),'Datasets/raw_data/movies/movie_lines.txt'),'rb').readlines()\n",
    "path = os.path.join(os.getcwd(),'Datasets/processed_data/movies/')\n",
    "tfile = open( os.path.join(path,\"movie_dialogues.txt\"), 'a+')\n",
    "tfile.write(for i in file.encode('ascii').replace('\\n\\'',\"\").replace('\\n\\\"',\"\").replace(\"\\n\",\"\"))\n",
    "tfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "79a02233-3e0e-4de9-a707-f74b443386fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "replace() argument 1 must be str, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mThey do not!\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: replace() argument 1 must be str, not list"
     ]
    }
   ],
   "source": [
    "\"They do not!\\n'\".replace('\\n\\'',\"\").replace('\\n\\\"',\"\").replace(\"\\n\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f6fa21be-9f9b-4744-9c2c-2ff6ee62a1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a string'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'a string'.encode('ascii').decode('ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "607c9471-8933-4e82-93c0-5037d0e56511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f3f1ca3-b670-484a-a1eb-e451cf6010fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading cl100k_base encoder from tiktoken library\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "# reading season1.txt file, which consists conversations from season 1 of friends\n",
    "s1data = open('Datasets/processed_data/friends/friends.txt').read()\n",
    "# encoding the entire season 1 data using cl100k_base encoder from OpenAI\n",
    "tokens = enc.encode(s1data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b62b302b-21c1-4e5c-9528-714b84ac8cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[220]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.encode(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "305bc4bb-26f8-4b69-88c3-3f6550f1c3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.decode([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77e6a56e-4850-498f-9146-0c60660eaffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Length:  1152879\n",
      "\n",
      "First 20 Encoded Tokens:  [11342, 3074, 480, 7218, 512, 3947, 596, 4400, 311, 3371, 0, 1283, 596, 1120, 1063, 7564, 358, 990, 449, 2268]\n",
      "\n",
      "First 20 Decoded Tokens:  Monica Geller:\n",
      "There's nothing to tell! He's just some guy I work with!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokens Length: \",len(tokens),end='\\n\\n')\n",
    "print(\"First 20 Encoded Tokens: \", tokens[:20],end='\\n\\n')\n",
    "print(\"First 20 Decoded Tokens: \", enc.decode(tokens[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d295cab6-198f-4e1f-838b-dbb4ab894fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17976\n"
     ]
    }
   ],
   "source": [
    "print(len(set(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e772356d-2c54-4e19-ba79-a65ec826f6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17984%64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "53bb6fc4-2b60-4f37-9679-13416c46f22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt_model_weights_14M_CP1.pth'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'gpt_model_weights_14M_CP%d.pth'%(5000//5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d476936-12d2-4195-99f9-4103b563312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Datasets/processed_data/friends/friends.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd5223b9-ec1c-4b9f-aade-9aabe27ba6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '}']\n"
     ]
    }
   ],
   "source": [
    "print(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288545b8-ab44-4042-86d9-912ffc77d881",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc78989e-b9cc-48a1-b1f9-e1341c576fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# batch_size = 128 # independent batches of sequencial text that are gonna process in parallel\n",
    "# block_size = 2048 # maximum context length of input sequence for predictions\n",
    "# max_iters = 50000 # total training loops\n",
    "# eval_interval = 500 # for evaluating the model periodically\n",
    "# learning_rate = 3e-4 # \n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu' # cuda will be used for training on GPU\n",
    "# eval_iters = 200\n",
    "# n_embd = 256 #size of the embedding layer\n",
    "# n_head = 16 # no.of self attention heads\n",
    "# n_layer = 16 # no.of hidden layers\n",
    "# dropout = 0.2 # dropout layers to avoid overfitting the model\n",
    "# vocab_size = len(set(tokens)) # no.of individual tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65eed9b7-d830-4892-bc3b-9935ae1da177",
   "metadata": {},
   "source": [
    "# Transformer Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0866b50-6406-4ff8-9491-a5fa0fdbebfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "43978cca-823a-462a-95fd-3c63617eda42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test splits\n",
    "data = torch.tensor([i for i in range(1,101)], dtype=torch.long)\n",
    "n = int(0.85*len(data)) # first 85% will be train and rest for validation\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "BATCH_INDEX = 0\n",
    "\n",
    "#\n",
    "batch_size = 4 # independent batches of sequencial text that are gonna process in parallel\n",
    "block_size = 8 \n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    global BATCH_INDEX\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.tensor([i for i in range(BATCH_INDEX, BATCH_INDEX+(batch_size*block_size), block_size)])\n",
    "    print(ix)\n",
    "    #block_list = [data[i:i+block_size] for i in ix]\n",
    "    block_list = data[ix[0]:ix[-1]+block_size +1 ]\n",
    "    x =[]\n",
    "    if len(block_list) < batch_size*block_size:\n",
    "        block_list = torch.cat( (block_list, torch.zeros( batch_size*block_size - len(block_list)+1 )), 0 )\n",
    "        #x = torch.stack(block_list)\n",
    "        x = torch.reshape(block_list[:-1],(batch_size,block_size))        \n",
    "    else:\n",
    "        #x = torch.stack(block_list)\n",
    "        x = torch.reshape(block_list[:-1],(batch_size,block_size)) \n",
    "        \n",
    "    #x = torch.reshape(block_list,(batch_size,block_size))\n",
    "    print(\"x: \",x)\n",
    "    \n",
    "    y = torch.reshape(block_list[1:],(batch_size,block_size)) \n",
    "    print(\"y: \",y)\n",
    "    \n",
    "    \n",
    "    BATCH_INDEX+= batch_size*block_size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0093ac84-d2ef-4784-aad2-53e9766b1436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1,2,3,4,5,6,7,8,9]\n",
    "# x[:-1] # except last\n",
    "x[1:] # except first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9c9d7f16-20ee-48e4-a286-384d2d0cf4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[220]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.encode(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0af08551-2bde-48e0-80cc-86c86636e5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 0.])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat( (torch.tensor([1 for i in range(4)])[:2], torch.zeros( 4*8 - 31)),0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "278dae47-730a-497c-a306-474ed88a189b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([i for i in range(4)])\n",
    "#a.view(2, 2)\n",
    "torch.reshape(a, (2, 2))\n",
    "# b = torch.tensor([[0, 1], [2, 3]])\n",
    "# torch.reshape(b, (-1,))\n",
    "torch.zeros(5)\n",
    "#torch.cat(a,  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "6e6bbebb-0b88-4959-9fff-42d1978103a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([220., 220., 220., 220., 220.])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(5)+220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e43a83d7-f425-45f9-977b-913adc4f7aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  8, 16, 24])\n",
      "x:  tensor([[ 1,  2,  3,  4,  5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12, 13, 14, 15, 16],\n",
      "        [17, 18, 19, 20, 21, 22, 23, 24],\n",
      "        [25, 26, 27, 28, 29, 30, 31, 32]])\n",
      "y:  tensor([[ 2,  3,  4,  5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23, 24, 25],\n",
      "        [26, 27, 28, 29, 30, 31, 32, 33]])\n"
     ]
    }
   ],
   "source": [
    "get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f51f077d-81f8-4350-8523-85882d36e06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([32, 40, 48, 56])\n",
      "x:  tensor([[33, 34, 35, 36, 37, 38, 39, 40],\n",
      "        [41, 42, 43, 44, 45, 46, 47, 48],\n",
      "        [49, 50, 51, 52, 53, 54, 55, 56],\n",
      "        [57, 58, 59, 60, 61, 62, 63, 64]])\n",
      "y:  tensor([[34, 35, 36, 37, 38, 39, 40, 41],\n",
      "        [42, 43, 44, 45, 46, 47, 48, 49],\n",
      "        [50, 51, 52, 53, 54, 55, 56, 57],\n",
      "        [58, 59, 60, 61, 62, 63, 64, 65]])\n"
     ]
    }
   ],
   "source": [
    "get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "092a5b9f-4bf8-4ec5-bc7e-fc1e5f4a6d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([64, 72, 80, 88])\n",
      "x:  tensor([[65., 66., 67., 68., 69., 70., 71., 72.],\n",
      "        [73., 74., 75., 76., 77., 78., 79., 80.],\n",
      "        [81., 82., 83., 84., 85.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "y:  tensor([[66., 67., 68., 69., 70., 71., 72., 73.],\n",
      "        [74., 75., 76., 77., 78., 79., 80., 81.],\n",
      "        [82., 83., 84., 85.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n"
     ]
    }
   ],
   "source": [
    "get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00935985-8a8c-41ce-a886-23a1384f64e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20b1e30e-7e0a-4626-890b-6be676627d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test splits\n",
    "data = torch.tensor(tokens, dtype=torch.long)\n",
    "n = int(0.85*len(data)) # first 85% will be train and rest for validation\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "BATCH_INDEX = 0\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    global BATCH_INDEX\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data    \n",
    "    ix = torch.tensor([i for i in range(BATCH_INDEX, BATCH_INDEX+(batch_size*block_size), block_size)])  \n",
    "    # this mechanism allows model to predict next token\n",
    "    # X tensor\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    # y tensor\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])    \n",
    "    x, y = x.to(device), y.to(device)\n",
    "    BATCH_INDEX += block_size*batch_size\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc139b5-eb99-4178-8827-d533ba917968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ccdcb2f-4acc-4add-86d4-52097b45b922",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c97a7a-6be1-4e7c-bca6-d2ab05eb35c0",
   "metadata": {},
   "source": [
    "# NLM architectue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "33de10a4-dd37-4113-8b81-2d212414895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Self-attention head from the transformers\n",
    "class Head(nn.Module):\n",
    "   \n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class GPTLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "        # better init, not covered in the original GPT video, but important, will cover in followup video\n",
    "        #self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        idx = idx.clamp(0, vocab_size - 1)  \n",
    "        tok_emb = self.token_embedding_table(idx) \n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.blocks(x) \n",
    "        x = self.ln_f(x) \n",
    "        logits = self.lm_head(x) \n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            # Clip the targets tensor to the valid range\n",
    "            targets = targets.clamp(0, vocab_size - 1)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):        \n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]            \n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:, -1, :] \n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)            \n",
    "            idx_next = torch.multinomial(probs, num_samples=1)         \n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d5e77921-cc2b-4fc3-810a-3257f1e3324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring Hyper-parameters\n",
    "\n",
    "batch_size = 64 # independent batches of sequencial text that are gonna process in parallel\n",
    "block_size = 512 # maximum context length of input sequence for predictions\n",
    "max_iters = 5000 # total training loops\n",
    "eval_interval = 500 # for evaluating the model periodically\n",
    "learning_rate = 3e-4 # \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # cuda will be used for training on GPU\n",
    "eval_iters = 200\n",
    "n_embd = 256 #size of the embedding layer\n",
    "n_head = 6 # no.of self attention heads\n",
    "n_layer = 4 # no.of hidden layers\n",
    "dropout = 0.2 # dropout layers to avoid overfitting the model\n",
    "vocab_size = 5864 #len(set(tokens)) # no.of individual tokens\n",
    "\n",
    "#\n",
    "baseModel = GPTLanguageModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ee2d4930-b389-4348-b1c6-6a80e918e6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading pre-trained weights with 6.2 million parameters\n",
    "baseModel.load_state_dict(torch.load('gpt_model_weights_6_2_M.pth', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "dade0a97-b0df-470e-9aa2-66f4ad3cb6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How you doing? I've went there too much way was here too. I was I'm Mich. What do. fil,. We have ever.... I think we do it'd have ever. I mean,... at the... ,a $7."
     ]
    }
   ],
   "source": [
    "# Text Generation\n",
    "\n",
    "context = torch.tensor([enc.encode(\"How you doing\")], dtype=torch.long, device='cpu')\n",
    "\n",
    "print(enc.decode(baseModel.generate(context, max_new_tokens=64)[0].tolist()).replace(\"inder\",\"\"), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d1f13873-ca64-41fd-8986-8dc42c4d5ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring Hyper-parameters for 10 million parameter model\n",
    "\n",
    "batch_size = 64 # independent batches of sequencial text that are gonna process in parallel\n",
    "block_size = 512 # maximum context length of input sequence for predictions\n",
    "max_iters = 500 # total training loops\n",
    "eval_interval = 500 # for evaluating the model periodically\n",
    "learning_rate = 3e-4 # \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # cuda will be used for training on GPU\n",
    "eval_iters = 200\n",
    "n_embd = 324 #size of the embedding layer\n",
    "n_head = 6 # no.of self attention heads\n",
    "n_layer = 5 # no.of hidden layers\n",
    "dropout = 0.2 # dropout layers to avoid overfitting the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ca9f445f-247a-41dc-b099-7e79e4fffa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModel10 = GPTLanguageModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6a601f35-8cbc-45d0-aa3c-8ba141845e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseModel10.load_state_dict(torch.load('gpt_model_weights_10M.pth', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c6844339-b0e7-4487-afb3-bc1467f0f4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi.? What almost you never other.? You and play I,, don't d' l? .., no no. th, it's, like, ok, it's., see, where are you know that's good, y', wait...? I mean, about theless rem74. it was. It's 'cause we thing. That is so great. We won't. We're never get off with you something. That's like this was a you know who doesn't youruff, my place"
     ]
    }
   ],
   "source": [
    "context = torch.tensor([enc.encode(\"Hi\")], dtype=torch.long, device='cpu')\n",
    "print(enc.decode(baseModel10.generate(context, max_new_tokens=128)[0].tolist()).replace(\"inder\",\"\"), end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42280e2-81ab-40c6-8a14-601c320f9d1a",
   "metadata": {},
   "source": [
    "# NLM  ASCII "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba9bf5d-1c4d-4521-9195-10048d3089be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bae953-f48f-491a-bb45-9425a22fbd76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf68a39-9453-45c4-80a5-fffda21513d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb8c0b8d-6d11-40f1-9eec-f62e35ae7fc8",
   "metadata": {},
   "source": [
    "# NLM 88M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "fded9c33-21b9-4413-82d8-a305e6eb11d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6da99113-2fb1-4a85-bfee-a4f510532bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5da44491-f920-4109-882f-d26abe265ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 24 # how many independent sequences will we process in parallel?\n",
    "block_size = 256 # what is the maximum context length for predictions?\n",
    "max_iters = 50000\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2\n",
    "vocab_size = enc.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b9b6c464-93c4-4d2a-bc5d-c841a659efc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModel88M = GPTLanguageModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8f28c4b0-011b-4306-aba3-c8b89e93ef3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseModel88M.load_state_dict(torch.load('/Users/krishna/Downloads/gpt_model_weights_88M_CP4_bnr.pth',\n",
    "#                                        map_location=torch.device('mps')))\n",
    "baseModel88M.load_state_dict(torch.load('/Users/krishna/Documents/UTA/Capstone/outputs/88M_friends/gpt_model_weights_88M_CP30_rk22.pth',\n",
    "                                       map_location=torch.device('mps')))\n",
    "\n",
    "# baseModel88M.load_state_dict(torch.load('/Users/krishna/Documents/UTA/Capstone/outputs/88M_friends/gpt_model_weights_88M_CP55_rk22.pth',\n",
    "#                                         map_location=torch.device('mps')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a985158a-ad66-417f-b0fe-067e975be5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ross: hey Joey do you wanna go out with your fine.\n",
      "\n",
      "Monica Geller:\n",
      "Oh, my god, I'm just ate it, \"Where are you?\n",
      "\n",
      "Ross Geller:\n",
      "No! No, I'm, no no way learn for a class I'm in again.\"\n",
      "\n",
      "Monica Geller:\n",
      "Excuse me?\n",
      "\n",
      "Joey Tribbiani:\n",
      "Great! Well hey, I'm here to meet you.\n",
      "\n",
      "Chandler Bing:\n",
      "Oh that's funny, hi. Yeah.\n",
      "\n",
      "Ross Geller:\n",
      "Hi!\n",
      "\n",
      "Phoebe Buffay:\n",
      "Oh you are so fine, please. I was fine, umm, and try the best goodnight from Aunt Single card in this craving for a lot.\n",
      "\n",
      "Phoebe Buffay:\n",
      "He's lace.\n",
      "\n",
      "Ross Geller:\n",
      "He's hair.\n",
      "\n",
      "Phoebe Buffay:\n",
      "Oh yeah. So what's up. What is it is great. Can I get up?\n",
      "\n",
      "Joey Tribbiani:\n",
      "He's gone. You remembered porn if we had plans to ride along with you in personal stuff, discussed... make. So you seen me?\n",
      "\n",
      "Phoebe Buffay:\n",
      "Well, maybe I should just set up town.\n",
      "\n",
      "Joey Tribbiani:\n",
      "All right, bye.\n",
      "\n",
      "Phoebe Buffay:\n",
      "Oh that's dead but, don't he wants to hear you, there's going in on that's taking it?\n",
      "\n",
      "Joey Tribbiani:\n",
      "Well, maybe he's never going him.\n",
      "\n",
      "Phoebe Buffay:\n",
      "Well, actually know how that he keeps across.\n",
      "\n",
      "Phoebe Buffay:\n",
      "He's feeling that guy says that he thinks she seems like a point where he gets stood from the bathroom, then, the ocean.\n",
      "\n",
      "Joey Tribbiani:\n",
      "I can't.\n",
      "\n",
      "Joey Tribbiani:\n",
      "There's no no no idea how the sex he's sweet, maybe it's too. You know what he wants to move on.\n",
      "\n",
      "Phoebe Buffay:\n",
      "He's not 't marmin' he should want, to leave his place could have gum?\n",
      "\n",
      "Joey Tribbiani:\n",
      "There he is the woman.\n",
      "\n",
      "Phoebe Buffay:\n",
      "Wait a big say this, you don't think I have one of those roses. But I never would get to Mike.\n",
      "\n",
      "Phoebe Buffay:\n",
      "Oooh! That thing!\n",
      "\n",
      "Joey Tribbiani:\n",
      "Don't worry about this. You know, heard? I have kissed Rachel, you have heard about the father.\n",
      "\n",
      "Phoebe Buffay:\n",
      "There he is! I want to kill you to know what? You know, I want to know"
     ]
    }
   ],
   "source": [
    "context = torch.tensor([enc.encode(\"Ross: hey Joey do you wanna go out\")], dtype=torch.long, device=torch.device('cpu'))\n",
    "print(enc.decode(baseModel88M.generate(context, max_new_tokens=512)[0].tolist()), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4461613-6fcf-4aa0-8565-ccf0a12ade7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
